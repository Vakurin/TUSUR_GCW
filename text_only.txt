Министерство науки и высшего образования российской федерации    

Федеральное государственное бюджетное образовательное 
учреждение высшего образования

ТОМСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ СИСТЕМ УПРАВЛЕНИЯ И РАДИОЭЛЕКТРОНИКИ (ТУСУР)

Кафедра автоматизированных систем управления (АСУ)

К ЗАЩИТЕ ДОПУСТИТЬ
    И.о. зав. кафедрой АСУ
канд. техн. наук, доцент  
___________ В.В. Романенко
     «___» __________20      г.

РАЗРАБОТКА СИНТЕТИЧЕСКИХ ДАННЫХ С ПОМОЩЬЮ 
ГЕНЕРАТИВНО-СОСТЯЗАТЕЛЬНЫХ СЕТЕЙ

Бакалаврская работа по направлению 09.03.01 
«Информатика и вычислительная техника»

 












Студент гр. 436-1
                           М.А. Вакурин

«___» _________ 2020 г.

Руководитель
Доцент кафедры АСУ
канд. техн. наук
                           В.Д. Сибилев
«___» _________ 2020 г.

 
Томск 2020           
Министерство науки и высшего образования российской федерации
Федеральное государственное бюджетное образовательное 
учреждение высшего образования
ТОМСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ СИСТЕМ
УПРАВЛЕНИЯ И РАДИОЭЛЕКТРОНИКИ (ТУСУР)
Кафедра автоматизированных систем управления (АСУ)

УТВЕРЖДАЮ
И.о. зав. кафедрой АСУ
канд. техн. наук, доцент  
_________ В.В. Романенко
«___» ____________2020 г.

ЗАДАНИЕ
к бакалаврской работе студенту Вакурину Максиму Алексеевичу, группа 
436 - 1, факультет систем управления

1. Тема бакалаврской работы (БР): «Разработка синтетических данных с помо-щью генеративно-состязательных сетей» 
(утверждена приказом по ВУЗу от «___» ____________2020 г. № _______)

2. Срок сдачи студентом законченной работы «  3  »    июля       2020 г.

3. Исходные данные к работе:
3.1 Техническое задание.
3.2 Список литературных источников по теме ВКР.
3.3 ОС ТУСУР 01–2013. Работы студенческие по направлениям подготов-ки и специальностям технического профиля. Общие требования и пра¬вила оформления.
 
4. Содержание расчетно-пояснительной записки / перечень подлежащих разра-ботке вопросов:
4.1 Обзор глубокого обучения и методов генераций.
4.2 Обзор архитектуры генерации.
4.3 Реализация архитектуры.

5. Перечень графического материала:
–	актуальность;
–	цели и задачи;
–	постановка задачи;
–	глубокое обучение;
–	генеративно-состязательные сети;
–	SinGAN;
–	архитектура SinGAN;
–	тренировка SinGAN;
–	используемые программные системы и аппаратные устройства;
–	результаты;
–	заключение.


6. Дата выдачи задания « 15  »        июня      2020 г.


Руководитель выпускной квалификационной работы
Доцент кафедры АСУ, канд. техн. наук
«        »                          2020 г.                           _____________ В.Д. Сибилев

Задание принято к исполнению 
«  15  »         июня        2020 г. 		      ______________М.А. Вакурин 
Реферат

	Пояснительная записка к бакалаврской работе содержит 40 страниц, 26 рисунков, 19 источников.
	ГЛУБОКОЕ ОБУЧЕНИЕ, СИНТЕТИЧЕСКИЕ ДАННЫЕ, GAN-СЕТИ, ГЕНЕРАТИВНО-СОСТЯЗАТЕЛЬНЫЕ СЕТИ.
Объектом данной работы является разработка системы для генерации син-тетических данных с помощью генеративно-состязательных сетей.
	Целью работы – получение модели глубокого обучения, где на входе сеть принимает одно изображение, а на выходе генерирует 50 изображений с разной степенью генерации и разной высотой и шириной, которые укажет пользова-тель.	Результатом разработки является сеть глубокого обучения, позволяющая создавать новые изображения, где на вход подаем одно изображение, а на выхо-де получаем сгенерированные изображения с разным соотношением сторон.
	Программная система реализована на языке программирования Python 3 с использованием библиотеки глубокого обучение PyTorch и с помощью сервиса для тренировки моделей Google Colab. Среда разработки – Jupyter Notebook, операционная система – Mac OS 10.15.
	Область применения – компании, заинтересованные в показе контента на разные устройства. 
	Пояснительная записка к ВКР выполнена в текстовом редакторе MS Word 2016.


 
Abstract
	The explanatory note to the final qualifying work contains 40 pages, 26 figures, 19 sources.
	DEEP LEARNING, SYNTHETIC DATA, GAN-NETWORKS, GENERA-TIVE ADVERSARIAL NETWORK.
	The object of this work is to develop a system for generated synthetic data with generative adversarial network.
	The aim of the work is to develop a system for generation synthetic data with GAN-Network.	
The result of development is a deep learning network that allows you to gener-ate new image by source image and generating new samples of arbitrary size and as-pect ratio.
	The software system is implemented in the Python 3 is a programming lan-guage which using additional framework PyTorch is a deep learning library and for training models Google Collaboratory. The development environment is Jupyter Notebook, the operating system is Mac OS 10.15.
	Explanatory note to the WRC is made in the text editor MS Word 2016.


 
Содержание
Введение	7
1   Обзор предметной области	8
1.1   Генеративное моделирование	8
1.2   Глубокое обучение	9
1.3   Генеративно-состязательные сети	10
1.4   Синтетические данные	12
1.5   Применение GAN и синтетических данных	14
1.6   Среда разработки	15
1.7   Язык разработки	16
2   Основные компоненты глубокого обучения	18
2.1   SinGAN	18
2.2   Архитектура сети	18
2.3   Архитектура Генератора	20
2.4   Архитектура Дискриминатора	21
2.5   Функция потерь	22
3   Разработка	23
3.1   Постановка задачи	23
3.2   Реализация архитектуры	23
3.3   Реализация штрафов градиента	24
3.4   Реализация одного шага обучения	26
3.5   Реализация тренировки	29
3.6   Реализация анимации	30
3.7   Реализация генерации изображений	31
3.8   Реализация изображений с разным соотношением сторон	32
3.9   Результаты	33
Заключение	37
Список использованных источников	39

Введение
        С каждым годом у нас становится все больше устройств и у каждого такого устройства свое соотношение сторон, из-за этого все сложнее делать контент, так как разработчикам и создателям контента приходится думать о десятках разных размеров.
Целью бакалаврской работы выбрана разработка сети глубокого обуче-ния, которая смогла бы получать на входе изображение одного размера и гене-рировать изображения с разными размерами, не теряя при этом необходимую информацию.
Следуя поставленной цели, в качестве основы, в данной работе выбрана технология Глубокого Обучения (Deep Learning), в ходе реализации которой планируется разработать инновационный принцип программной обработки по-ступающих на вход изображений одного размера и последующей генерации изображений других размеров на выходе.
Целью выпускной квалификационной работы является разработка про-граммной системы генерации изображений с разным соотношением сторон по одному входному изображению, но других размеров. Для решения поставлен-ной цели были выполнены следующие задачи:
1)	изучены особенности глубоких и генеративных сетей;
2)	выполнен обзор по методам применения генеративных сетей;
3)	разработана архитектура сети, применимой для сетей глубокого обучения, которая принимает на вход одно изображение, а на выходе генерирует несколь-ко изображений разных размеров по сравнению с размерами оригинала;
4)	проведен полный разбор всех слоев, которые нужны для реализации сети глубокого обучения;
5)	проведено тестирование по разработанной модели глубокого обучения.

1   Обзор предметной области

1.1   Генеративное моделирование
Один из ярких примеров генеративного моделирования [1] — это челове-ческое воображение. Человек может закрыть глаза и представить все, что ему захочется. Нейробиологи предполагают, что наше восприятие реальности осно-вывается на генеративном моделировании – с рождения мы можем моделиро-вать наше окружение, которое соответствует настоящему.
Генеративное моделирование можно описать так: у нас есть набор дан-ных, которые генерируются с точки зрения вероятностной модели. Используя эту модель, можно получить новые данные. Если хотим создать новое изобра-жение, то нам нужен будет обучающий набор с похожим классом изображений. Целью является создание модели, способной генерировать признаки, выглядя-щие настоящими. В задачах генерации роль признаков обычно несут пиксели изображения.
Основные математические обозначения в генеративном моделировании описывают через p(x) - вероятность получения наблюдения Х. Если набор дан-ных содержит метки, то можно построить генеративную модель, оценивающую распределение p(x|y). В итоге модель не учитывает метки наблюдения и оцени-вает вероятность того, что сгенерированный образец похож на остальные наблюдения.
Базовые принцип генеративного моделирования:
-	имеется набор изображений X;
-	предполагается, что изображения сгенерированы с некоторым неиз-вестным распределением p_data;
-	генеративная модель p_model пытается имитировать p_data. С её по-мощью можем генерировать наблюдения, которые выглядят похожи-ми на p_data;
-	p_model работает правильно, если она генерирует образцы, которые выглядят аналогично полученным из p_data, и при этом не копирует образцы, отличающиеся от изображений Х.
Этим основным принципам и следует генеративное моделирование.
1.2   Глубокое обучение
Методы глубокого обучение [2] возникли еще в 1980-ом году, но с увели-чением объема данных и ростом вычислительных мощностей, эта сфера начала набирать популярность и появились первые результаты. Многие алгоритмы стали осуществимы и начали превосходить то, что было до их реализации.
Модели глубокого обучения способны самостоятельно выявлять высоко-уровневые информативные признаки из неструктурированных данных (аудио, видео, фотографий). Когда речь заходит о генерации данных, то сфера глубоко-го обучения показывает всю силу, поэтому основные принципы Deep Learning используются в генеративном моделировании.
Большинство систем глубокого обучения представляют собой нейронные сети с несколькими скрытыми слоями, наложенными друг на друга. В общих чертах, каждый слой содержит нейроны, связанные с узлами в соседнем слое посредством набора весов (весовых коэффициентов). Чаще всего используются «полносвязные» слои, которые соединяются друг с другом. Глубокие сети мо-гут иметь любое количество скрытых слоев. Сила глубоких сетей заключается в их способности находить наборы весов для каждого слоя, дающего наиболее точные прогнозы. Процесс поиска весов называется обучением.
Основным «топливом» для глубокого обучения становятся данные: это могут быть аудио, видео материалы, фотографии, рисунки и т. п. Благодаря данным, сеть способна находить повторяющиеся элементы и извлекать из них признаки, которые помогут в работе сети.
С каждым годом данных становится все больше, однако при этом полу-чить их все труднее. К примеру, недавний европейский закон о защите персо-нальных данных (GDPR) [3], в котором обработка данных стала юридической процедурой и теперь просто так не собрать данные о пользователе, нужен акт о согласии пользователя на обработку его данных. Кроме того, данные должны быть зашифрованными, а передача третьим лицам – запрещена. Компании обя-заны иметь сотрудника, ответственного за безопасность этих данных (data protection officer). Если личные данные пользователей будут утеряны или раз-глашены, то это грозит компаниям, допустившим подобное, многомиллионны-ми штрафными санкциями. Развитие глубокого обучения может замедлиться из-за бюрократических обязательств, и все меньше компаний будут заинтересо-ваны в разработке проектов, основанных на нейронных сетях.
1.3   Генеративно-состязательные сети
Одна из самых развивающихся областей глубокого обучения называется GAN (Generative Adversarial Networks) или генеративно-состязательные сети – это такие сети, которые способны генерировать или восстанавливать любой вид медиа файла, начиная с окраски черно-белого изображения в цветное, заканчи-вая созданием приятной человеческому восприятию музыки. Каждый месяц вы-ходят десятки статей о GAN-сетях, лучшие умы человечества работают в этой области, многие издания считают, что это самая прорывная и перспективная сфера за последние 10 лет.
В 2016 году, на конференции Neural Informatiom Processing Systems (NIPS) в Барселоне, Ян Гудфеллоу [4], руководитель отдела глубокого обучения из Google Brains, представил доклад под названием «Generative Adversatial Network» [5]. Его идеи, освещенные в той работе, в настоящее время рассматри-ваются как один из поворотных моментов в развитии генеративного моделиро-вания, и с тех пор появилось множество вариаций решений на тему генератив-ных сетей.
Генеративно-состязательные сети — это борьба между генератором и дис-криминатором. Генератор пытается преобразовать случайный шум в изображе-ние или любой медиа файл, который должен выглядит так, будто выбран из ре-альных образцов данных. Дискриминатор пытается понять, являются ли предо-ставленные ему данные настоящими или фейковым (фальшивыми).
В начале процесса генератор выводит искаженные изображения, а дис-криминатор оценивает их случайным образом. Основная особенность GAN - попеременное обучение двух подсетей: генератор постепенно совершенствуется в обмане дискриминатора, а дискриминатор, адаптируясь, учится правильно определять фальшивые наблюдения, что заставляет генератор искать новые спо-собы обмана дискриминатора.
 
Рисунок 1.1 - Архитектура GAN [6]
1.4   Синтетические данные
Глубокое обучение набирает все больше и больше популярности в наше время, одним из важнейших факторов такой популярности являются данные. В качестве примеров источников возникновения данных приводятся непрерывно поступающие данные с измерительных устройств, потоки сообщений из социальных сетей, метеорологические данные, потоки данных о местонахож-дении абонентов сетей сотовой связи, устройств аудио- и видео-регистрации. Эти данные становятся «Мотором» для глубокого обучения, позволяя обучать модель, предсказывать результаты по наборам входных данных.
С непрерывно растущим объемом данных возникает проблема их обра-ботки. Для многих задач нужна разметка или маска в данных, а чтобы разметить данные требуется много часов работы человека, ведь как правило зачастую это делается вручную. Из-за этого разметка данных становится достаточно затрат-ным процессом. Как пример невозможности получения исходных для обработ-ки данных – это необходимость дополнительного использования специальных устройств (датчиков, сенсоров, приборов ночного видения и т. п.), без которых, например, получить реальную глубину изображения практически невозможно. Поэтому используются синтетические данные, когда достаточно создать 3D мо-дель и её окружение и поместить это в среду разработки, в результате чего эму-лируется искомая разметка контролируемым программным процессом.
На практике возможно создавать 3D-модели интересующих нас объектов (вручную) и помещать их в необходимое виртуальное окружение, а затем воз-можно генерировать изображения, как рендеры 3D-сцен с различных точек зре-ния. Таким образом на выходе могут быть сгенерированы изображения, как кадры из мультфильма, и при этом вполне возможно «запечатлеть» необходи-мые объекты со всех сторон, в любых комбинациях и ракурсах. Важно, что раз-метка методами синтетической генерации получается автоматически и абсо-лютно идеально. Самостоятельно создав 3D-сцену и разместив камеру, мы в со-стоянии безошибочно понимать, к какому объекту относится буквально каждый пиксель полученного рендера.
 
Рисунок 1.2 - Пример синтетических данных
Синтетические данные особенно хорошо работают в задачах «компьютер-ного зрения» [7]. То есть в задачах, где искусственному интеллекту нужно рас-познавать объекты на фотографиях или в окружающем его мире в режиме ре-ального времени. Впервые синтетические данные начали применять в беспи-лотных автомобилях, создавая программные симуляции вождения задолго до тестов на реальных дорогах и с реальными людьми.
1.5   Применение GAN и синтетических данных
Многие крупные IT-компании активно исследуют GAN-сети, существует множество примеров удачных решений. Одним из таких примером, стала сеть от компании Nvidia, которая называется StyleGAN2 [8] – эта сеть создает лица людей, которых не существует в реальности. Они даже сделали отдельных сайт This Person Does't Exist [9], где можно посмотреть на сгенерированные лица с помощью нейронной сети. Это впечатляющие результаты, чтобы понять, что эти сгенерированные изображения отличить от настоящих практически невоз-можно.
 
Рисунок 1.3 - Все лица сгенерированы с помощью StyleGAN2 и их не существу-ет
Компания OpenAI [10], занимающаяся разработкой искусственного ин-теллекта, представила GPT-3 [11] — модель, которая в состоянии «писать» це-лые абзацы осмысленного текста. Компания проводила исследования, в ходе которых обычные люди и даже профессионалы не могли понять кто написал этот текст – робот или человек. По результатам впечатляющих исследований, компания приняла решение не предоставлять открытый доступ к данной нейронной сети, так как с её помощью вполне вероятно могли бы создаваться поддельные новости и другие небылицы, а это уже грозило бы судебными раз-бирательствами.
Одним из примеров взаимодействия синтетических данных и GAN-сетей является SimGAN [12]. Компания Apple обучила модель на синтетических дан-ных, улучшенных при помощи SimGAN. Суть была такова: они сделали 3D-модель глаза и с помощью GAN-сетей сделали более реалистичное изображе-ние.
 
Рисунок 1.4 - Пример работы SimGAN
1.6   Среда разработки
Основная среда разработки была Jupyter Notebook [13]. Это бесплатная научная среда с открытым программным кодом, которая предназначена для ра-боты с большими данными, глубоким обучением и построением математиче-ских моделей. Чтобы запустить её, нам нужно установить библиотеку jupyter в Python и после она запускается на локальном хосте. Весь интерфейс состоит из ячеек, которые можно запускать в произвольном порядке. Здесь можно делать все основные этапы разработки моделей для глубокого обучения: подготовку, очистку, трансформацию, тренировку и визуализацию данных.

 
Рисунок 1.5 - Интерфейс Jupyter Notebook

Один из основных минусов — это отсутствие отладчика кода, но это лег-ко исправляется с помощью установки дополнительных модулей.
1.7   Язык разработки
В качестве основного языка программирования выступает язык програм-мирования «Python» [14] или питон.
Python появился в 90-ых как скриптовый язык программирования, но с каждым годом становился все мощнее и популярнее. Теперь на нем можно де-лать все, начиная от веб-приложений и заканчивая анализом данных. В сфере глубокого обучения и всем, что связанно с машинным обучением, питон зани-мает первое место среди разработчиков. Все основные фреймворки для работы с глубоким обучением написаны для Python, один из них это PyTorch.
PyTorch — это библиотека для работы с машинным обучением от компа-нии Facebook. С помощью него можно легко создавать нейронные сети и тре-нировать свои модели. Он позволяет импортировать модели на сервер, умень-шать модели и запускать на мобильных устройствах, а также производить кван-товые вычисления. Вычисления внутри библиотеки происходит с помощью графов состояний.
 
2   Основные компоненты глубокого обучения

2.1   SinGAN
Данная работа посвящена реализации сети SinGAN [15], которая способна генерировать из одного входного статичного изображения разные образцы по соотношению сторон, а также его анимированные варианты. На рисунке 2.1 по-казано, как из самого левого столбца сеть генерирует разные изображения (вправо). С помощью данной сети возможно по единому образцу генерировать контент с разным соотношением сторон и, самое главное, сохраняя структуру изображения – то есть важные атрибуты изображения. Реализуемая сеть отлич-но иллюстрирует возможности манипулирования изображениями.
 
Рисунок 2.1 - Пример работы сети
2.2   Архитектура сети
В данной главе рассмотрим общую архитектуру сети, а в последующих – её внутренние особенности. При построении глубокой сети самым важным ас-пектом является архитектура. Какие будут внутренние слои и как они будут взаимодействовать между собой. Есть входной слой, принимающий входные данные, есть выходной слой, откуда снимается результат работы нейросети, а между ними присутствуют также скрытые слои. В случае, когда скрытых слоев больше одного, то нейросеть считается глубокой. Неглубокая сеть содержит всего один такой слой. Данная работа описывает архитектуру сети SinGAN.
SinGAN в значительной степени универсальный метод, который может из одного изображения сгенерировать анимацию или создать другое разрешение изображения. Особенностью данного метода является обучение по всего одному изображению. Архитектура SinGAN имеет структуру пирамиды, состоящую из N слоев, а модель обучается снизу вверх (начиная с нижнего слоя и заканчивая последним верхнем слоем). Дело в том, что процесс обучения делится на N эта-пов. Масштаб изображения, вводимого в каждый слой, отличается, и масштаб постепенно увеличивается от слоя к слою.
Алгоритм по методу SinGAN:
1.	Вводится шум z_N в генератор G_N, чтобы создать первый образец x_N.
2.	Повышается размер x_N и вводится в G_(N-1) вместе с шумом z_(N-1) для создания нового образца изображения x_1.
3.	Операции 1 и 2 повторяются до G_0.
4.	Изображение с каждого G образца сравнивается с реальным изображени-ем посредством дискриминатора.
В итоге, из шума создается новое изображение с основными особенностями и атрибутами исходного изображения.
 
Рисунок 2.2 - Архитектура сети
2.3   Архитектура Генератора
Генератор отвечает за создание изображений из гауссовского шума. Все бло-ки генератора имеют похожую архитектуру, которая состоит из Гауссовского Шума, Свёрточного слоя, Батч-нормализации и Leaky-Relu. О каждой из этих составляющих подробнее:
-	Гауссовский шум (Zn) – определённым образом объединяется с изображени-ем из предыдущей итерации (операция сложения), если предыдущей опера-ции не было, то подается только шум. Здесь важно подавать шум до сверх-точных слоев, чтобы сеть не «забыла» о нём.
-	Свёрточные слои (Convolutional Layers) — это операция перемножения ядра свертки на изображение. Ядро проходит над изображением, поэлементно вы-полняя операцию умножения с той частью входных данных, над которой оно сейчас находится, и затем суммирует все полученные значения в один вы-ходной пиксель. Это нужно для того, чтобы определить признаки или сущ-ности на изображении, которые в результате будут объединены для получе-ния нового признака на выходе. Задача этого слоя – генерация на каждом шаге пропущенных деталей.
-	Батч-нормализация (Batch Normalization) - этот слой используется для со-кращения времени обучения модели. Метод решает следующую проблему, препятствующую эффективному обучению нейронных сетей: по мере рас-пространения сигнала по сети, даже если он нормализован на входе, пройдя через внутренние слои, он может сильно исказиться как по математическому ожиданию, так и по дисперсии (данное явление называется внутренним кова-риационным сдвигом), что чревато серьезными несоответствиями между градиентами на различных уровнях. Для этого используется батч-нормализация, которая делает решение проще: нормализует входные данные таким образом, чтобы получить нулевое математическое ожидание и еди-ничную дисперсию. Нормализация выполняется перед входом в каждый об-рабатываемый слой.
-	Leaky-Relu – вычисление значения функции f(x) = max(0.01, x), которое ре-шает проблему обнуления градиента для положительных чисел и очень про-сто вычисляется.
 
Рисунок 2.3 - Архитектура генератора
2.4   Архитектура Дискриминатора
Архитектура дискриминатора представляет собой аналогичную генерато-ру архитектуру, с одной лишь особенностью – в ней не используется шум. На вход сети подаётся сгенерированное изображение, и то же самое производится с оригинальным изображением, затем они сравниваются и вычисляется общая ошибка или функция потерь, которая уже далее передается в генератор.
2.5   Функция потерь
Функция потерь — это основная формула, отвечающая за генерацию изоб-ражения, с помощью нее сеть учится и пытается уменьшить ошибку. Она состо-ит из двух подфункций:
-	Ladv – штраф-функция, которая считает на сколько отличается сгенери-рованное изображение от настоящего,
-	Lrec – функция-арбитр, отвечающая за то, чтобы все важные элементы изображения сохранились.
 
Рисунок 2.4 - Формула функции-потерь

Принципиально важно убедиться, что сгенерированное изображение не отличается от оригинала катастрофически. Для этого используется Lrec, где сначала обнуляется подающийся генератору шум, а затем полученное изобра-жение вычитается из оригинального изображения по квадрату (формула пред-ставлена на рисунке 2.5).

 
Рисунок 2.5 - Формула реконструктивной функции потерь
3   Разработка

3.1   Постановка задачи
Задача - разработать нейронную сеть SinGAN, которая из одного статиче-ского изображения на входе генерирует на выходе анимированные и статиче-ские изображения с разным соотношением сторон.
3.2   Реализация архитектуры
Архитектура сети — это основополагающий фундамент в реализации си-стемы глубокого обучения.
В процессе реализации архитектуры сети глубокого обучения создан файл под названием models.py, в котором реализовано два базовых класса: класс ге-нератора (рис 3.1) и класс дискриминатора (рис 3.2).
В методе __init__ инициализируются необходимые переменные, а метод forward отвечает за то, в какой последовательности будут использованы слои нейронной сети – это стандартная практика для классов с глубокими сетями.

 
Рисунок 3.1 - Реализация класса генератор
 
Рисунок 3.2 - Реализация класса дискриминатора
Также создан класс блока со свёрточными сетями под названием ConvBlock (рис. 3.3), где вызываются уже реализованные методы из PyTorch, такие как Conv2d, BatchNorm2d, LeakyReLU. Этот класс используется в генера-торе и в дискриминаторе.
 
Рисунок 3.3 - Реализация класса ConvBlock
3.3   Реализация штрафов градиента
Создана дополнительная функция для штрафования градиента (рис 3.4) или, как её еще называют, WGAN-GP [16]. Смысл этой функции в том, чтобы штрафовать дискриминатор за его ошибки, если он не угадал, где реальное изображение а где подделка. Это реализовано с целью стабилизации обучения в GAN-сетях. Обычно используется бинарная перекрестная энтропия [17], однако на практике она дает неравномерную сходимость генератора и дискриминатора, из-за чего обучение нестабильно, поэтому, для повышения стабильности обуче-ния, в данной работе используется WGAN_GP. Эта штраф-функция пытается максимизировать разницу между оценками для реальных и сгенерированных изображений, при этом реальные изображения получают более высокую оцен-ку.
При использовании такой функции дискриминатор обучается сходимости, что обеспечивает правильное изменение градиентов, используемых для обнов-ления генератора. Благодаря такому подходу дискриминатор не становится слишком «сильным», и это позитивно сказывается на генерации изображений. Стандартные подходы WGAN_GP тренировки, должны обучить несколько раз дискриминатор между обновлениями генератора. Типичное соотношение: пять обновлений дискриминатора на одно обновление генератора.
В самом начале создается число alpha в диапазоне от 0 до 1, после чего оно расширяется посредством метода expand() до размеров настоящего изобра-жения и передается на GPU. Далее высчитывается интерполяция изображения, определяется значение дискриминатора и находится значение градиента c по-мощью метода torch.autograd.grad(), который в свою очередь определяет сумму градиентов.

 
Рисунок 3.4 - Функция штрафов WGAN-GP

Функция потерь штрафа за градиент измеряется, как квадрат разности между нормой градиента прогнозов для входных изображений и единицей.
3.4   Реализация одного шага обучения
В процессе выполнения программного кода из файла training.py будет происходить тренировка, но сначала необходимо реализовать хотя бы один шаг обучения, и только после этого запускать полный цикл тренировки.
В начале реализованы оптимизаторы и коэффициенты скорости обучения. В качестве оптимизатора используется метод Адам [18], который можно приме-нять вместо классической процедуры стохастического градиентного спуска для итеративного обновления весов сети на основе обучающих данных. Адам явля-ется эффективным методом и можем быстрее достичь задаваемой сходимости. Далее реализован коэффициент скорости обучения или learning rate [19], c по-мощью которого принимается решение, с какой скоростью следует двигаться по градиентному спуску. Все эти функции являются стандартными в PyTorch. В данной работе эти функции объявляются и для генератора и для дискриминато-ра.
 
Рисунок 3.5 - Оптимизаторы и коэффициенты скорости обучения
Также необходимо реализовать обновление сетей посредством Функции потерь — это функции, которые помогают обучаться алгоритму, то есть пере-дают градиент в нейронную сеть и пытаются оптимизировать эту функцию для лучших результатов.
С целью обновления генератора используется реконструкционная функ-ция потерь (Глава 2.4). В самом начале делается зануление градиента с помо-щью netG.zero_grad(). Это необходимо потому, что PyTorch накапливает гради-ент при последующих обратных проходах. Далее определяется оценка, которую даст дискриминатор на входное сгенерированное изображение и считается сред-нее значение оценок. Затем высчитывается обратная ошибка и выполняется ре-конструкционная функция потерь, где в конце вызывается метод detach(), так как PyTorch отслеживает все операции, которые связаны с тензором и записыва-ет их граф, поэтому данный метод прекращает отслеживание и запись в граф, что позволяет более оптимально использовать память компьютера и таким об-разом позволяет работать с миллионами данных. С помощью метода step() об-новляется оптимизатор Генератора.
 
Рисунок 3.6 - Обновление генератора
Обновление дискриминатора происходит по схожей схеме, как и обновле-ние генератора, только здесь не вычисляется реконструкционная функция по-терь, а используется значение среднеквадратичной ошибки и корня между настоящим изображением и сгенерированным. Далее вызывается функция штрафов градиента functions.calc_gradient_penalty() и определяется распро-странение обратной ошибки для нее. Затем складывается значение штрафа со значением дискриминатора по сгенерированным и настоящим изображением, и уже из этого результата получается функция потерь дискриминатора.
 
Рисунок 3.7 - Обновление дискриминатора
3.5   Реализация тренировки
Одна из немаловажных функций – это функция обучения (train), без нее никаких результатов просто не будет. Процесс тренировки прост: начинаем с маленького размера изображения и постепенно увеличиваем размер пока не до-стигнем заданного нами значения (в данном случае это 250 на 250 пикселей). Конкретный пример: начинаем с изображения размером 25 на 25 пикселей и каждую итерацию обработки по сети будем увеличивать на 25 пикселей по всем соотношениям, следовательно, нам потребуется 10 таких увеличений, чтобы программа остановилась на размере 250. При этом данная функция также про-изводит пересчет градиентов посредством функции train_single_scale (Глава 3.4).
 
Рисунок 3.8 - Реализация тренировки
Если будем уменьшать количество уменьшений и прибавлять больше пикселей на каждой итерации, то у нас могут получиться некачественные изоб-ражения, отличающиеся от исходного образца. На рисунке 3.7 показана зависи-мость качества от количества увеличений изображения – чем меньше увеличе-ний делаем, тем хуже сгенерированный образец. Поэтому оптимальный выбор, это около 8-10 увеличений шума, который поступает на вход генератору.
 
Рисунок 3.9 - Зависимость качества изображения от увеличения
3.6   Реализация анимации
В ходе реализации процесса анимации создан файл animation.py, про-граммный код из которого будет вызываться через командную строку, где должны быть указаны имя файла изображения, на котором будет проводиться обучение. Программный код показан на рисунке 3.6, где в начале создаем ди-ректорию для сохранения наших результатов. После выбираем либо обучение, либо загрузку имеющегося обучения в случае, если такая директория уже суще-ствует с ранее сгенерированными файлами. После обучения программой гене-рируется gif-файл с несколькими степенями анимации – от самой слабой до са-мой сильной.
 
Рисунок 3.10 - Реализация запуска анимации
3.7   Реализация генерации изображений
В процессе генерации изображения в самом начале генерируется шум. В зависимости от того, какого размера будет сгенерирован шум, такого же разме-ра и будет генерироваться изображение. В результате сгенерируется 50 экзем-пляров изображений, из которых затем можно будет выбрать лучшие. Изобра-жение генерируется из шума посредством генератора, а затем сохраняется в файл.
 
Рисунок 3.11 - Реализация генерации изображения
3.8   Реализация изображений с разным соотношением сторон
Создан дополнительный файл для запуска генерации изображений через терминал. Флаг mode указывает на то, что именно требуется сгенерировать. Ес-ли выбран random_samples, то на выходе будут сгенерированы образцы с таким же размером, как и исходное изображение, а если же выбран random_samples_arbitraty_sizes, то задаем дополнительно, какого размера долж-ны быть сгенерированы выходные изображения.
 
Рисунок 3.12 - Реализация запуска генерации через терминал
3.9   Результаты
Для тестирования сети возьмем два изображения. Первое изображение (рис 3.13) обработаем сетью с помощью GPU или Графического процессора от компании Nvidia 2070 Super.  Не будем выставлять никаких дополнительных параметров, просто сгенерируем 50 образцов с разной степенью генерации.
 
Рисунок 3.13 - Тестовое изображение №1

Так, после одного часа обучения, получаем 3 директории. При самой сла-бой генерации разница между сгенерированными и исходным изображениями будет едва заметна, а при самой высокой генерации (рис. 3.14) разница будет более заметна: сеть уменьшает крону дерева или сжимает само дерево, делая его ниже.
 
Рисунок 3.14 - Результаты после самой сильной генерации
Второе изображение (рис. 3.15), будем генерировать с разным соотноше-нием сторон.
 
Рисунок 3.15 - Тестовое изображение №2

У нас исходное изображение размером 250 на 250 пикселей, хотим попро-бовать сделать это изображение шире, к примеру 325 на 175, или сделать выше 175 на 325. Результаты работы сети показаны на рисунке 3.16.
 
Рисунок 3.16 - Результаты работы генерации по высоте и ширине

Создание с анимации занимает такое же количество времени, при этом на выходе генерируется 12 gif-файлов с разной степенью анимации.









Заключение
В ходе выполнения бакалаврской работы были изучены основные понятия глубоких сетей, рассмотрены основные технологии для реализации генератив-ных моделей. 
Были рассмотрены некоторые области применения GAN-сетей на основе этого было доказана актуальность данной сферы во многих отраслях производ-ства.
На стадии обзора были рассмотрены основные языки программирования для глубоких сетей, изучены их возможности, описаны их основные преимуще-ства и недостатки. 
Опираясь на всю полученную информацию, было принято решение раз-работать сеть глубокого обучения, предоставляющую из себя программу для генерации синтетических данных. 
На стадии проектирования ПО было принято решение использовать язык программирования Python, так как он содержит все необходимые функции для реализации. Были изучены основные инструменты для создания глубоких сетей – фреймворки для Python. 
На стадии разработки были реализованы все необходимые функции:
	загрузка файла изображения;
	реализация архитектуры сети;
	генерация несколько видов изображения с разными размерами;
	генерация анимации из статичного изображения;
	сохранение изображения;
	песочница для языка Python, для работы с основными библиотеками анализа данных.
Используя описанные в данной работе идеи и их реализацию, у производителей контента не должно возникнуть проблем с адаптацией контента под разные экраны устройств.
Таким образом, была достигнута основная цель, которая была упомянута во введении, и как следствие, можем считать, что цель выпускной квалификацион-ной работы была достигнута в полном объёме.
Пояснительная записка выполнена в соответствии с ОС ТУСУР 01–2013 «Рабо-ты студенческие по направлениям подготовки и специальностям технического профиля».
 
Список использованных источников
1.	Генеративное Моделирование и AI [Электронный ресурс] - Режим досту-па: https://habr.com/ru/post/347184/
2.	Deep Learning [Электронный ресурс] - Режим доступа: https://en.wikipedia.org/wiki/Deep_learning
3.	General Data Protection Regulation [Электронный ресурс] - Режим доступа: https://gdpr-info.eu
4.	Ian Goodfellow [Электронный ресурс] - Режим доступа: https://en.wikipedia.org/wiki/Ian_Goodfellow
5.	Generative Adversarial Networks [Электронный ресурс] - Режим доступа: https://arxiv.org/abs/1406.2661
6.	Vanilla GAN Architecture [Электронный ресурс] - Режим доступа: https://financeandriskblog.accenture.com/analytics/how-generative-adversarial-networks-can-impact-banking
7.	Computer Vision [Электронный ресурс] - Режим доступа: https://en.wikipedia.org/wiki/Computer_vision
8.	StyleGAN 2 [Электронный ресурс] - Режим доступа: https://github.com/NVlabs/stylegan2.git
9.	This Person Does Not Exist [Электронный ресурс] - Режим доступа: https://thispersondoesnotexist.com
10.	OpenAI [Электронный ресурс] - Режим доступа: http://openai.com
11.	GPT-3 [Электронный ресурс] - Режим доступа: https://openai.com/blog/openai-api/
12.	Learning from Simulated and Unsupervised Images through Adversarial Train-ing [Электронный ресурс] - Режим доступа: https://arxiv.org/abs/1612.07828
13.	Jupyter Notebook [Электронный ресурс] - Режим доступа: https://jupyter.org
14.	Python [Электронный ресурс] - Режим доступа: https://www.python.org
15.	SinGAN Learning a Generative Model from a Single Natural Image [Элек-тронный ресурс] - Режим доступа: https://arxiv.org/abs/1905.011
16.	WGAN-GP [Электронный ресурс] - Режим доступа: https://arxiv.org/pdf/1704.00028.pdf
17.	Cross entropy [Электронный ресурс] - Режим доступа:  https://en.wikipedia.org/wiki/Cross_entropy 
18.	Adam: A Method for Stochastic Optimization [Электронный ресурс] - Режим доступа: https://arxiv.org/abs/1412.6980
19.	Learning rate [Электронный ресурс] - Режим доступа: https://en.wikipedia.org/wiki/Learning_rate 


