Министерство науки и высшего образования российской федерации    

Федеральное государственное бюджетное образовательное 
учреждение высшего образования

ТОМСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ СИСТЕМ УПРАВЛЕНИЯ И РАДИОЭЛЕКТРОНИКИ (ТУСУР)

Кафедра автоматизированных систем управления (АСУ)

К ЗАЩИТЕ ДОПУСТИТЬ
    И.о. зав. кафедрой АСУ
канд. техн. наук, доцент  
___________ В.В.Романенко
     «___» __________20      г.

Разработка синтетических данных с  помощью генеративных-состязательных сетей
Бакалаврская работа
 по направлению 09.03.01 «Информатика и вычислительная техника»
 














Студент гр. 436-1
                           М.А. Вакурин

«___» _________ 2020 г.

Руководитель
Проф. каф. АСУ, к.т.н,
                           В.Д. Сибилев
«___» _________ 2020 г.


 
Томск 2020           
Министерство науки и высшего образования российской федерации
Федеральное государственное бюджетное образовательное 
учреждение высшего образования
ТОМСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ СИСТЕМ
УПРАВЛЕНИЯ И РАДИОЭЛЕКТРОНИКИ (ТУСУР)
Кафедра автоматизированных систем управления (АСУ)

УТВЕРЖДАЮ
   И.о. зав. кафедрой АСУ
канд. техн. наук, доцент  
__________ В.В.Романенко
«___» ____________2020 г.


ЗАДАНИЕ

к бакалаврской работе студенту Вакурину Максиму Алексеевичу, группа 
436 - 1, факультет систем управления
1. Тема бакалаврской работы (БР): «Разработка синтетических данных с  помощью генеративных-состязательных сетей» (утверждена приказом по ВУЗу от «___» ____________2020 г. № _______)
2. Срок сдачи студентом законченной работы « 3 »    июля       2020 г.
3. Исходные данные к работе:
3.1 Техническое задание.
3.2 Список литературных источников по теме ВКР.
3.3 ОС ТУСУР 01–2013. Работы студенческие по направлениям подготовки и специальностям технического профиля. Общие требования и пра¬вила оформления.
 
4. Содержание расчетно-пояснительной записки / перечень подлежащих разработке вопросов:
4.1 Обзор глубокого обучения и методов генераций.
4.2 Обзор архитектуры генерации. 
4.3 Реализация архитектуры. 

5. Перечень графического материала(с точным указанием обязательных листов презентации):
1.	Актуальность
2.	Цели и задачи
3.	Глубокое обучение
4.	Генеративно-состязательные сети
5.	SinGAN
6.	Архитектура SinGAN
7.	Тренировка SinGAN
8.	Используемые программные системы и аппаратные устройства
9.	Результаты 
10.	 Результаты
11.	 Заключение 
6. Дата выдачи задания «15»        июня      2020 г.
Руководитель выпускной квалификационной работы

Доцент кафедры АСУ ТУСУР,  к.т.н.,          
«         »                         2020 г.                           _____________ В.Д. Сибилев


Задание принято к исполнению 
«15»           июня          2020 г. 		      ______________М.А. Вакурин 

Реферат
	Пояснительная записка к бакалаврской работе содержит 44 страниц, 26 рисунков, 19 источников.
	ГЛУБОКОЕ ОБУЧЕНИЕ, СИНТЕТИЧЕСКИЕ ДАННЫЕ, GAN-СЕТИ, ГЕНЕРАТИВНО-СОСТЯЗАТЕЛЬНЫЕ СЕТИ.
Объектом данной работы является разработка системы для генерации синтетических данных с помощью генеративных-состязательных сетей.
	Цель работы – получение модели глубокого обучения, где на входе сеть принимает одно изображение, а на выходе получаем 50 изображений с разной степенью генерации и разной высотой и шириной, которую укажет пользователь.
	Результатом разработки является сеть глубокого обучения, позволяющая создавать новые изображения, где на вход подаем одно изображение, а на выходе получаем сгенерированные изображения с разным соотношением сторон. 
	Программная система реализована на языке программирования Python 3 с использованием библиотеки глубокого обучение PyTorch и с помощью сервиса для тренировки моделей Google Colab. Среда разработки – Jupyter Notebook, операционная система – Mac OS 10.15.
	Область применения – компании, заинтересованные в показе контента на разные устройства. 
	Пояснительная записка к ВКР выполнена в текстовом редакторе MS Word 2016.


 
Abstract
	The explanatory note to the final qualifying work contains 45 pages, 26 figures, 17 sources.
	DEEP LEARNING,  SYNTHETIC DATA, GAN-NETWORKS, GENERATIVE ADVERSARIAL NETWORK.
	The object of this work is to develop a system for generated synthetic data with generative adversarial network.
	The aim of the work is to develop a system for generation synthetic data with GAN-Network.	
The result of development is a deep learning network that allows you to generated new image by source image and generating new samples of arbitrary size and aspect ratio.
	The software system is implemented in the Python 3 is a programming language witch using additional framework PyTorch is a deep learning library and for training models Google Collaboratory. The development environment is Jupyter Notebook, the operating system is Mac OS 10.15.
	Explanatory note to the WRC is made in the text editor MS Word 2016.


 
Содержание
Введение	5
1. Обзор предметной области	6
1.1 Генеративное моделирование	6
1.2  Глубокое обучение	7
1.3 Генеративно-состязательные сети	9
1.4 Синтетические данные	10
1.5 Применение GAN и синтетических данных	12
1.6 Среда разработки	14
1.7 Язык разработки	15
2 Основные компоненты глубокого обучения	16
2.1 SinGAN	16
2.2 Архитектура сети	17
2.3 Архитектура Генератора	18
2.4 Архитектура Дискриминатора	20
2.5 Функция потерь	20
3 Разработка	22
3.1 Постановка задачи	22
3.2 Реализация архитектуры	22
3.3 Реализация штрафов градиента	24
3.4 Реализация одного шага обучения	25
3.5 Реализация тренировки	30
3.6 Реализация анимации	32
3.7 Реализация генерации изображений	33
3.8 Реализация картинок с разным соотношением сторон	34
3.9 Результаты	35
Заключение	40
Список использованных источников	41



















Введение
        С каждым годом у нас становится все больше устройств и у каждого такого устройства свое соотношение сторон, из-за этого все сложнее делать контент, так как разработчикам и создателям контента приходится думать о десятках разных размеров.
Именно поэтому целью бакалаврской работы выбрана разработка сети глубокого обучения, которая смогла бы брать изображение одного размера и генерировать изображения с разными размерами, не теряя при этом необходимую информацию.
Вот почему вектором развития был выбран Deep Learning или Глубокое обучение, который может генерировать разные изображения и обрабатывать их.
Целью выпускной квалификационной работы является разработка программной системы генерации изображений с разным соотношением сторон по одной входной картинке отличительного размера. Для решения поставленной цели необходимо выполнить следующие задачи:
1)	изучить особенности глубоких и генеративных сетей;
2)	выполнить обзор по методам применения генеративных сетей;
3)	разработать архитектуру сети применимой для сетей глубокого обучения, которая на вход бы принимала одно изображение, а на выходе генерировала несколько изображений разного размера, отличительного от оригинала;
4)	провести полный разбор всех слоев, которые нужны для реализации сети глубокого обучения;
5)	провести тестирование по разработанной модели глубокого обучения.
1. Обзор предметной области

1.1 Генеративное моделирование
Один из ярких примеров генеративного моделирования[1] - это человеческое воображение, человек может закрыть глаза и представить все, что угодно. Нейробиологи предполагают, что наше восприятие реальности основывается на генеративном моделировании, с рождения можем моделировать наше окружение, которое соответствует настоящему.
Генеративное моделирование можно описать так: у нас есть набор данных, которые генерируются с точки зрения вероятностной модели. Используя эту модель, можно получить новые данные. Если хотим создать новое изображение, то нам нужен будет обучающий набор с похожим классом картинок. Целью является создание модели способную генерировать признаки, которые выглядят, как настоящие. В задачах генерации роль признаков обычно являются пиксели картинки.
Основные математические обозначения в генеративном моделировании описывают через p(x) - вероятность получения наблюдения Х. Если набор данных содержит метки, то можно построить генеративную модель, оценивающую распределение p(x|y). В итоге, модель не учитывает метки наблюдения и оценивает вероятность того, что сгенерированный образец похож на остальные наблюдения.
Базовые принцип генеративного моделирования:
-	У нас есть набор изображений X
-	Предполагаем, что изображения сгенерированы с некоторым неизвестным распределением p_data.
-	Генеративная модель p_model пытается имитировать p_data. С её помощью можем генерировать наблюдения, которые выглядят похожими на p_data.
-	p_model правильно работает, если: 
1.	Генерирует образцы, которые выглядят так, будто получены из p_data
2.	Если сгенерированные образцы, отличаются от изображений X, то есть она не должна их копировать.
Этим основным принципам и следует генеративное моделирование.

1.2  Глубокое обучение
Методы глубокого обучение[2] возникли еще в 1980-ом году, но именно с увеличением объема данных и ростом вычислительных мощностей, эта сфера начала набирать популярность и появились первые результаты. Многие алгоритмы стали осуществимы и начали превосходить то , что было до этого.
Модели глубокого обучения способны сами выявить высокоуровневые информативные признаки из неструктурированных данных(аудио, изображения). Когда речь заходит о генерации данных, то сфера глубокого обучения показывает всю силу, поэтому основные принципы  Deep Learning используются в генеративном моделировании.
Большинство систем глубокого обучения представляют собой нейронные сети с несколькими скрытыми слоями, наложенными друг на друга. В общих чертах, каждый слой содержит нейроны, связанные с узлами в предыдущем слое посредством набора весов (весовых коэффициентов). Чаще всего используются полносвязные слои, которые соединяются друг с другом. Глубокие сети могут иметь любое количество скрытых слоев. Сила глубоких сетей заключается в их способности находить наборы весов для каждого слоя, дающего наиболее точные прогнозы. Процесс поиска весов называется обучением.
Основным "топливом" для глубокого обучения становятся данные: это могут быть изображения, аудио, видео. Благодаря данным, сеть может находить паттерны и извлекать из них признаки, которые помогут в работе сети.
Хоть с каждым годом данных становится все больше, но получить их все труднее. К примеру, недавний европейский закон о защите персональных данных(GDPR)[3], в котором обработка данных стала юридической процедурой и теперь просто так не собрать данные о пользователе, нужен акт о согласии пользователя. Кроме того, данные должны быть зашифрованными, а передача третьим лицам - запрещена. Компании обязаны иметь сотрудника, который будет отвечать за безопасность этих данных(data protection officer). Если личные данные пользователя будут утеряны, то это грозит компании многомиллионным штрафом. Развитие глубокого обучения может замедлиться из-за бюрократических обязательств, и все меньше компаний будут хотеть сделать проекты с нейронными сетями.
1.3 Генеративно-состязательные сети
Одна из самых развивающихся областей глубокого обучения называется GAN(Generative Adversarial Networks) или генеративные состязательные сети, это такие сети , которые могут сгенерировать или восстановить любой вид медиа файла, начиная с окраски черно-белого изображения в цветное, заканчивая созданием музыки. Каждый месяц выходят десятки статей про GAN-сети, лучшие умы человечества работают над этой технологией, многие издания также считают, что это самая “прорывная” сфера за последние 10 лет.
В 2016 году на конференции Neural Informatiom Processing Systems (NIPS) в Барселоне Ян Гудфеллоу[4] руководитель отдела глубокого обучения из Google Brains, представил доклад под названием "Generative Adversatial Network"[5]. Идеи, представленные в докладе, теперь рассматриваются как один из поворотных моментов в развитии генеративного моделирования, и с тех пор появилось множество вариаций на тему генеративных сетей.
Генеративно-состязательные сети - это борьба между генератором и дискриминатором. Генератор пытается преобразовать случайный шум в изображение или любой медиа файл, который должен выглядит так, будто выбран из реальных образцов данных, дискриминатор пытается понять являются ли данные, которые ему дали ,настоящими или фейком.
В начале процесса генератор выводит искаженные изображения, а дискриминатор оценивает их случайным образом. Основная особенность GAN - попеременное обучение двух подсетей: генератор постепенно совершенствуется в обмане дискриминатора, а дискриминатор, адаптируясь, учится правильно определять фальшивые наблюдения, что заставляет генератор искать новые способы обмана дискриминатора.
 
Рисунок 1.1 - Архитектура GAN[6].
1.4 Синтетические данные
Не случайно глубокое обучение набирает все больше и больше популярности в наше время, одним из важнейших факторов являются данные. В качестве примеров источников возникновения данных приводятся непрерывно поступающие данные с измерительных устройств, потоки сообщений из социальных сетей, метеорологические данные, потоки данных о местонахождении абонентов сетей сотовой связи, устройств аудио- и видеорегистрации. Эти данные становятся “Мотором” для глубокого обучения, позволяя обучать модель , предсказывать результат по набору входных данных.
С данными возникает проблема, для многих задач нужна разметка или маска в данных, чтобы разметить данные нужно много часов работы человека, так как это всегда делается в ручную. Из-за этого разметка данных становиться очень дорогой. Еще один случай, когда не можем получить данные, так как для этого требуется специальный сенсор, к примеру, нам нужна карта глубины изображения. Поэтому нам нужно использовать синтетические данные, нужно лишь сделать 3D модель или окружение и поместить в среду разработки, после этого разметка получается сама, так как  контролируем этот процесс и в большинстве случаев получаем разметку, которую не может сделать человек.
Можем сделать 3D-модели интересующих нас объектов (вручную) и поместить их в нужное виртуальное окружение, а затем порождать картинки как рендеры этих 3D-сцен. Будут получаться кадры из «мультфильма», и можем «снять» нужные объекты со всех сторон, в любых комбинациях и ракурсах. Очень важно, что разметка тоже получается автоматически и абсолютно идеально. Раз мы сами создали эту 3D-сцену и сами разместили камеру, теперь можем понять, к какому объекту относится буквально каждый пиксель полученного рендера.
 
Рисунок 1.2 — Пример синтетических данных.
Синтетические данные хорошо работают в задачах компьютерного зрения[7]. То есть в задачах, где искусственному интеллекту нужно распознать объекты на фотографиях или в окружающем его мире. Впервые синтетические данные начали применять в беспилотных автомобилях, делали симуляцию вождения, так как некоторые случаи могут стоить человеческой жизнью.
1.5 Применение GAN и синтетических данных
Каждая крупная IT-компания исследует GAN-сети, есть множество примеров удачных решений. Одним из таких примером, стала сеть от компании Nvidia, которая называется StyleGAN2[8] - создает лица людей, которых не существует. Они даже сделали отдельных сайт This Person Does't Exist[9], где можно посмотреть на сгенерированные лица с помощью нейронной сети. Это впечатляющие результаты, чтобы понять, что эти сгенерированные картинки отличить от настоящих практически невозможно.
 
Рисунок 1.3 - Все лица сгенерированны с помощью StyleGAN2 и их не существует.
Компания OpenAI[10], занимающаяся разработкой искусственного интеллекта, представила GPT-3[11] - это такая модель, которая может писать целые абзацы осмысленного текста. Компания проводила исследования и люди не могли понять, написал этот текст робот или человек, из-за чего компания не выложила в открытый доступ нейронную сеть, так как с помощью неё можно было писать поддельные новости и это бы грозило судом.
Одним из примеров взаимодействия синтетических данных и GAN-сетей - это SimGAN[12]. Компания Apple обучила модель на синтетических данных, улучшенных при помощи SimGAN. Суть была такова: они сделали 3D-модель глаза и с помощью GAN-сетей сделали более реалистичное изображение.
 
Рисунок 1.4 - Пример работы SimGAN.
1.6 Среда разработки
Основная среда разработки была Jupyter Notebook[13]. Это бесплатная научная среда с открытым программным кодом, которая предназначена для работы с большими данными, глубоким обучением и построением математических моделей. Чтобы запустить её, нам нужно установить библиотеку jupyter в Python и после она запускается на локальном хосте. Весь интерфейс состоит из ячеек, которые можно запускать в произвольном порядке. Здесь можно делать все основные этапы разработки моделей для глубокого обучения: подготовку, очистку, трансформацию, тренировку и визуализацию данных.

 
Рисунок 1.5 - Интерфейс Jupyter Notebook.
Один из основных минусов - это отсутствие отладчика кода, но это легко исправляется с помощью установки дополнительных модулей.
1.7 Язык разработки
В качестве основного языка программирования выступает язык программирования «Python»[14] или питон.
Python появился в 90-ых как скриптовый язык программирования, но с каждым годом становился все мощнее и популярнее. Теперь на нем можно делать все, начиная от веб-приложений и заканчивая анализом данных. В сфере глубокого обучения и всем , что связанно с машинным обучением, питон занимает первое место среди разработчиков. Все основные фреймворки для работы с глубоким обучением написаны для Python, один из них это PyTorch.
PyTorch - это библиотека для работы с машинным обучением от компании Facebook. С помощью него можно легко создавать нейронные сети и тренировать свои модели. Также он позволяет импортировать модели на сервер, уменьшать модели и запускать на мобильных устройствах, а также производить квантовые вычисления. Вычисления внутри библиотеки происходит с помощью графов состояния.






2 Основные компоненты глубокого обучения

2.1 SinGAN
В моей выпускной работе я буду реализовать сеть SinGAN[15] - это сеть, которая умеет делать из одного изображения разные образцы по соотношению сторон, а так же может анимировать статичное изображение. На рисунке 2.1 показано как из самого левого столбца сеть может сгенерировать разные изображения. С помощью неё можем по единому образцу генерировать контент с разным соотношением сторон и, самое главное, сохраняя структуру изображения, то есть важные атрибуты изображения. Эта сеть отлично иллюстрирует как можно манипулировать с изображениями.
 
Рисунок 2.1 - Пример работы сети.
2.2 Архитектура сети
В этой главе рассмотрим общую архитектуре сети, а в последующих все внутренности сети. При построении глубокой сети самым важным аспектом является архитектура. Какие будут внутренние слои и как они будут взаимодействовать между собой. Есть входной слой, куда подается входной сигнал, есть выходной слой, откуда снимается результат работы нейросети, и между ними есть скрытые слои. Если скрытых слоев больше, чем 1, нейросеть считается глубокой, если 1, то неглубокой. Глубокой нейронной сеткой является сетка , у которой больше одного скрытого слоя. В моей работе разберем архитектуру сеть SinGAN.
SinGAN в значительной степени универсальный метод, который может из одной картинки сгенерировать анимацию или сделать другое разрешение изображения. Кроме того, обучение выполняется с одним изображением. Архитектура SinGAN имеет структуру пирамиды, состоящую из N слоев, и модель обучается, начиная с нижнего слоя и заканчивая последним верхнем слоем. Дело в том, что этап обучения делится на N этапов. Масштаб изображения, вводимого в каждый слой, отличается, и масштаб постепенно увеличивается по сравнению с изображением меньшего масштаба.
Алгоритм следующий SinGAN:
1.	Вводится шум z_N в генератор G_N, чтобы создать первый образец x_N.
2.	Повысим размер x_N и введем в G_(N-1) вместе с шумом z_(N-1) для создания нового образца изображения x_1.
3.	Повторите это до G_0.
4.	Изображение с каждого G образца сравнивается с реальным изображение через дискриминатор.
В итоге, из шума создается новое изображение с основными особенностями атрибутами исходного изображения.
 
Рисунок 2.2 - Архитектура сети.


2.3 Архитектура Генератора
Генератор отвечает за создание изображений из гаусовского шума. Все блоки генератора имеют похожую архитектуру, которая состоит из гаусовского Шума, сверточного слоя, батч-нормализации и Leaky-Relu, о каждом из эти Х методов подробней:
-	Гаусовсовский шум(Zn) - складывается с картинкой из пред. итерации, если предыдущей операции не было, то подается только шум, важно, чтобы подавался шум до сверхточных слоев, тогда точно уверены , что сеть не забудет про шум.
-	Сверточные слои(Convolutional Layers) - это операция перемножения ядра свертки на изображение. Ядро проходит над изображением, поэлементно выполняя операцию умножения с той частью входных данных, над которой оно сейчас находится, и затем суммирует все полученные значения в один выходной пиксель. Это нужно для того, чтобы определить признаки или сущности на картинки, которые будут объединены для получения нового признака на выходе. Цель этого слоя в генерации на каждом шаге, пропущенных деталей.
-	Батч-нормализация(Batch Normalization) - этот слой используют для уменьшения времени тренировки модели. Метод решает следующую проблему, препятствующую эффективному обучению нейронных сетей: по мере распространения сигнала по сети, даже если нормализовали его на входе, пройдя через внутренние слои, он может сильно исказиться как по математическому ожиданию, так и по дисперсии (данное явление называется внутренним ковариационным сдвигом), что чревато серьезными несоответствиями между градиентами на различных уровнях. Из-за чего используем батч-нормализацию, которая делает очень простое решение: нормализует входные данные таким образом, чтобы получить нулевое матожидание и единичную дисперсию. Нормализация выполняется перед входом в каждый слой.
-	Leaky-Relu - Она вычисляет функцию f(x) = max(0.01, x). Это решает проблему обнуления градиента для положительных чисел и очень просто вычисляется.
 
Рисунок 2.3 - Архитектура генератора.
2.4 Архитектура Дискриминатора
Архитектура дискриминатора представляется из себя то же самое, что и архитектура генератора только без использования шума. Подаем на вход сети сгенерированное изображение и то же самое делаем с настоящей, потом сравниваем их и считаем общую ошибку или функция потерь, которая передается в генератор.
2.5 Функция потерь
Функция потерь - это основная формула, отвечающая за генерацию изображения , с помощью нее сеть учится и пытается уменьшить ошибку. Она состоит из двух под-функций:
-	Ladv - штраф-функция, которая считает на сколько отличается сгенерированное изображение от настоящего.
-	Lrec - смотрит, чтобы все важные элементы картинки сохранились.
 
Рисунок 2.4 - Формула функции-потерь.
Нам нужно убедиться, что сгенерированное изображение не сильно отличается от оригинала. Для этого используем Lrec. поэтому должны занулить шум, который подаем генератору, получить изображение, и вычесть из оригинальной по квадрату, формула представлена на рисунке 2.5.

 
Рисунок 2.5 - Формула реконструктивной функции потерь.







3 Разработка

3.1 Постановка задачи
Передо мной поставлена задача - разработать нейронную сеть SinGAN, которая сможет анимировать изображении и создавать изображения с разным соотношением сторон.
3.2 Реализация архитектуры
Самое первое, что нужно сделать - это написать архитектуру сети. Архитектура сети - это основная вещь в глубоком обучении.
Для реализации создадим файл под названием models.py, в нем необходимо реализовать два класса с генератором(рис 3.1) и дискриминатором(рис 3.2).
В методе __init__ инициализируем переменные которые будем использовать, а метод forward отвечает за то, в какой последовательности будут использованы слои нейронной сети; это стандартная практика для классов с глубокими сетями.

 
Рисунок 3.1 - Реализация класса генератор.
 

Рисунок 3.2 - Реализация класса дискриминатора.
Также создали блок со сверточными сетями и называли его ConvBlock (рис. 3.3), где вызываем уже реализованные методы из PyTorch, такие как Conv2d, BatchNorm2d, LeakyReLU. Это класс вызывается в генераторе и дискриминаторе.
 
Рисунок 3.3 - Реализация класса ConvBlock.

3.3 Реализация штрафов градиента
Создали дополнительную функцию для штрафования градиента (рис 3.4) или, как его еще называют, WGAN-GP[16]. Суть в том, что штрафуем дискриминатор за ошибки, если он не угадал, где реальное изображение. Это сделано для того, чтобы стабилизировать обучение в GAN-сетях. Обычно используется бинарная перекрестная энтропия[17], но она дает плохую сходимость генератора и дискриминатора из-за чего обучение нестабильно, поэтому лучше использовать WGAN_GP. Этот штраф пытается максимизировать разницу между оценками для реальных и сгенерированных изображений, при этом реальные изображения получают более высокую оценку.
При использовании такой функции, дискриминатор обучается сходимости, что обеспечивает правильное изменение градиентов, используемых для обновления генератора. Благодаря такому подходу дискриминатор не становится слишком “сильным”, и это позитивно сказывается на генерации изображений. Стандартные подходы WGAN_GP тренировки, должны обучить несколько раз дискриминатор между обновлениями генератора. Типичное соотношение: пять обновлений дискриминатора на одно обновление генератора.
В самом начале создаем число alpha, это одно число в диапазоне от 0 до 1, после это число расширяем с помощью метода expand() до размеров настоящего изображения и передаем на GPU. Далее считаем интерполяцию изображения, смотрим значение дискриминатора и считаем значение градиента c помощью метода torch.autograd.grad(), который автоматически считает сумму градиентов.

 
Рисунок 3.4 - Функция штрафов WGAN-GP.
Функция потерь штрафа за градиент измеряется, как квадрат разности между нормой градиента прогнозов для входных изображений и 1.

3.4 Реализация одного шага обучения
Создадим файл training.py в котором будет происходить тренировка, но сначала нужно реализовать один шаг обучения, а после запускать полный цикл тренировки.
В начале реализуем оптимизаторы и коэффициенты скорости обучения. В качестве оптимизаторов будем использовать Адам[18], который можно использовать вместо классической процедуры стохастического градиентного спуска для итеративного обновления весов сети на основе обучающих данных. Адам является эффективным методом и можем быстрее достичь нужной нам сходимости. Далее реализуем коэффициент скорости обучения или learning rate[19], c помощью этого коэффициента можем решить, с какой скоростью нам двигаться по градиентному спуску, все эти функции являются стандартными в PyTorch и объявим их для Генератора и Дискриминатора.
 
Рисунок 3.5 - Оптимизаторы и коэффициенты скорости обучения.
Еще нужно реализовать обновление сетей или ,как еще их называют, Функции потерь - это функции, которые помогают учиться алгоритму, то есть передают градиент в нейронную сеть и пытаются оптимизировать эту функцию для лучших результатов.
Начнем с обновления генератора, считаем с помощью реконструкционной функции потерь (Глава 2.4). В самом начале делаем зануление градиента с помощью netG.zero_grad() это нужно делать перед стартом обратной распространения ошибки, это сделано потому что PyTorch накапливает градиент при последующих обратных проходах. Далее смотрим какую оценку даст дискриминатор на наше сгенерированное изображение и считаем среднее значение оценок. Далее считаем обратную ошибку и делаем реконструкционую функцию потерь, где в конце вызываем метод detach(), так как PyTorch отслеживает все операции, которые связаны с тензором и записывает их граф, то с помощью этого метода, можем прекратить отслеживания и записывание в граф, помогает оптимально использовать память компьютера, таким образом позволяет работать с миллионами данных. С помощью метода step() обновляем оптимизатор Генератора.
 
Рисунок 3.6 - Обновление генератора.
Обновление дискриминатора происходит по похожей схеме, что и генератора, только тут не считаем реконструкционную функцию потерь, а считаем с помощью среднеквадратичной ошибкой и корня, между настоящим изображение и сгенерированным. Еще вызываем функцию штрафов градиента functions.calc_gradient_penalty() и считаем распространение обратной ошибки для нее. После складываем значения штрафа с значением дискриминатора по сгенерированными и настоящим изображениям из этого значения, получается функция потерь дискриминатора.
 
Рисунок 3.7 - Обновление дискриминатора.
3.5 Реализация тренировки
Одна из важнейших функций-train, без нее никаких результатов не может быть. Процесс тренировки прост: начинаем с маленького размера изображения и постепенно увеличиваем размер пока не достигнем заданного нами значения(в нашем случаи это 250 на 250 пикселей). Опишу на примере,  начинаем с картинки 25 на 25 пикселей и каждую итерацию прогона по нашей сети будем увеличивать на 25 пикселей по всем соотношениям, следовательно, нам нужно 10 таких увеличений, чтобы программа остановилась. Так же внутри этой функции происходит пересчет градиентов, с помощью функции train_single_scale о которых было рассказано в главе 3.4.
 
Рисунок 3.8 - Реализация тренировки.
Если будем уменьшать количество уменьшений и прибавлять больше пикселей на каждой итерации, то у нас могут получиться плохие изображения, отличные от исходного образца. На рисунке 3.7 показана зависимость от количества от увеличений изображения, чем меньше увеличений делаем, тем хуже сгенерированный образец. Поэтому оптимальный выбор, это около 8-10 увеличений шума, который поступает на вход генератору.
 
Рисунок 3.9 - Зависимость качества картинки от увеличения.
3.6 Реализация анимации
Процесс анимации очень прост, создаем файл animation.py который будет вызываться через командную строку, где должны указать имя файла, фотографии на которой будем обучать. Листинг тренировки показан на рисунке 3.6, где в начале создаем директорию для сохранения наших результатов. После выбираем либо тренировку, либо загрузку прошлой тренировки, если такая директория уже существует с тренировочными файлами. После тренировки генерируется gif-файл с несколькими степенями анимации от самой слабой до самой сильной.
 
Рисунок 3.10 - Реализация запуска анимации.
3.7 Реализация генерации изображений
Чтобы сгенерировать изображения в начале генерируем шум, в зависимости от того какого размера шум сделаем - такая и будет генерироваться изображение, будет генерироваться 50 экземпляров, из которых сможем выбрать потом самые лучшие. Генерируем из шума с помощью генератора и потом сохраняем сгенерированный образец.
 
Рисунок 3.11 - Реализация генерации изображения.
3.8 Реализация картинок с разным соотношением сторон
Создадим дополнительный файл для запуска генерации изображений через терминал, создаем флаг mode через который будем указывать, что именно хотим генерировать, если выбрали random_samples, то генерируем образцы с таким же размером как, и исходное, а если random_samples_arbitraty_sizes, то задаем какого размера должны генерироваться изображения.
 
Рисунок 3.12 - Реализация запуска генерации через терминал.


3.9 Результаты
Для тестирования сети возьмем два изображения. Первое изображение(рис 3.13) прогоним через сеть с помощью GPU или Графического процессора от компании Nvidia 2070 Super.  Не будем выставлять никаких дополнительных параметров, а просто сгенерируем 50 образцов с разной степенью генерации.
 
Рисунок 3.13 - Тестовое изображение №1.
Так после одного часа обучения получаем 3 директории. При самой слабой генерации там заметны несильно заметна разница, а при самом высокой генерации(рис. 3.14), можем увидеть разницу, как сеть уменьшает крону дерева или просто сжимает само дерево, делая его ниже.
 
Рисунок 3.14 - Результаты после самой сильной генерации.


Второе изображение(рис. 3.15), будем генерировать с разным соотношением сторон.
 
Рисунок 3.15 - Тестовое изображение №2.
У нас исходное изображение размером 250 на 250 пикселей, хотим попробовать сделать это изображение шире к примеру 325 на 175 или сделать выше 175 на 325, и можем так сделать с помощью сети, все результаты показаны на рисунке 3.16.
 
Рисунок 3.16 - Результаты работы генерации по высоте и ширине.
Работа с анимацией занимает такое же количество времени и формирует 12 gif-файлов с разной степенью анимации.









Заключение
В ходе выполнения бакалаврской работы были изучены основные понятия глубоких сетей, рассмотрены основные технологии для реализации генеративных моделей. 
Были рассмотрены некоторые области применения GAN-сетей на основе этого было доказана актуальность данной сферы во многих отраслях производства.
На стадии обзора были рассмотрены основные языки программирования для глубоких сетей, изучены их возможности, описаны их основные преимущества и недостатки. 
Опираясь на всю полученную информацию, было принято решение разработать сеть глубокого обучения, предоставляющую из себя программу для генерации синтетических данных. 
На стадии проектирования ПО было принято решение использовать язык Python, так как он удобен и содержит все необходимые функции для реализации. Были изучены основные инструменты для удобного создания глубоких сетей – фреймворки для Python. 
На стадии разработки были реализованы все основные функции:
	загрузка файла изображения;
	реализация архитектуры сети;
	генерация несколько видов изображения с разными размерами;
	генерация анимации из статичного изображения;
	сохранение изображения;
	песочница для языка Python, для работы с основными библиотеками анализа данных;
Список использованных источников
1.	Генеративное Моделирование и AI [Электронный ресурс] - Режим доступа: https://habr.com/ru/post/347184/
2.	Deep Learning [Электронный ресурс] - Режим доступа: https://en.wikipedia.org/wiki/Deep_learning
3.	General Data Protection Regulation [Электронный ресурс] - Режим доступа: https://gdpr-info.eu
4.	Ian Goodfellow [Электронный ресурс] - Режим доступа: https://en.wikipedia.org/wiki/Ian_Goodfellow
5.	Generative Adversarial Networks [Электронный ресурс] - Режим доступа: https://arxiv.org/abs/1406.2661
6.	Vanilla GAN Architecture [Электронный ресурс] - Режим доступа: https://financeandriskblog.accenture.com/analytics/how-generative-adversarial-networks-can-impact-banking
7.	Computer Vision [Электронный ресурс] - Режим доступа: https://en.wikipedia.org/wiki/Computer_vision
8.	StyleGAN 2 [Электронный ресурс] - Режим доступа: https://github.com/NVlabs/stylegan2.git
9.	This Person Does Not Exist [Электронный ресурс] - Режим доступа: https://thispersondoesnotexist.com
10.	OpenAI [Электронный ресурс] - Режим доступа: http://openai.com
11.	GPT-3 [Электронный ресурс] - Режим доступа: https://openai.com/blog/openai-api/
12.	Learning from Simulated and Unsupervised Images through Adversarial Training [Электронный ресурс] - Режим доступа: https://arxiv.org/abs/1612.07828
13.	Jupyter Notebook [Электронный ресурс] - Режим доступа: https://jupyter.org
14.	Python [Электронный ресурс] - Режим доступа: https://www.python.org
15.	SinGAN Learning a Generative Model from a Single Natural Image [Электронный ресурс] - Режим доступа: https://arxiv.org/abs/1905.011
16.	WGAN-GP [Электронный ресурс] - Режим доступа: https://arxiv.org/pdf/1704.00028.pdf
17.	Cross entropy [Электронный ресурс] - Режим доступа:   https://en.wikipedia.org/wiki/Cross_entropy 
18.	Adam: A Method for Stochastic Optimization [Электронный ресурс] - Режим доступа: https://arxiv.org/abs/1412.6980
19.	Learning rate [Электронный ресурс] - Режим доступа: https://en.wikipedia.org/wiki/Learning_rate 


